<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Glossary 3 (Factor Analysis) | Final Glossary Bookdown</title>
  <meta name="description" content="Final Glossary" />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Glossary 3 (Factor Analysis) | Final Glossary Bookdown" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Final Glossary" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Glossary 3 (Factor Analysis) | Final Glossary Bookdown" />
  
  <meta name="twitter:description" content="Final Glossary" />
  

<meta name="author" content="Marina Obata" />


<meta name="date" content="2020-06-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="glossary-2-pca.html"/>
<link rel="next" href="glossary-4-mca-ca.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Marina Obata final glossary</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Index for final Glossary</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#glossary-entries"><i class="fa fa-check"></i><b>1.1</b> 1.Glossary entries</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#glossary--pca-"><i class="fa fa-check"></i><b>1.2</b> 2.Glossary -PCA-</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#glossary--factor-analysis-"><i class="fa fa-check"></i><b>1.3</b> 3.Glossary -Factor Analysis-</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#glossary--mcaca-"><i class="fa fa-check"></i><b>1.4</b> 4.Glossary -MCA,CA-</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#glossary--cluster-analysis-"><i class="fa fa-check"></i><b>1.5</b> 5.Glossary -Cluster analysis-</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html"><i class="fa fa-check"></i><b>2</b> Glossary entries</a><ul>
<li class="chapter" data-level="2.1" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#exploratory-data-analysis-eda"><i class="fa fa-check"></i><b>2.1</b> Exploratory Data Analysis (EDA)</a></li>
<li class="chapter" data-level="2.2" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#principal-component-analysis-pca"><i class="fa fa-check"></i><b>2.2</b> Principal Component Analysis (PCA)</a></li>
<li class="chapter" data-level="2.3" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#factor-analysis"><i class="fa fa-check"></i><b>2.3</b> Factor Analysis</a></li>
<li class="chapter" data-level="2.4" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#cluster-analysis"><i class="fa fa-check"></i><b>2.4</b> Cluster Analysis</a></li>
<li class="chapter" data-level="2.5" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#correspondence-analysis-ca"><i class="fa fa-check"></i><b>2.5</b> Correspondence Analysis (CA)</a></li>
<li class="chapter" data-level="2.6" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#eigenvalues"><i class="fa fa-check"></i><b>2.6</b> Eigenvalues</a></li>
<li class="chapter" data-level="2.7" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#eigenvectors"><i class="fa fa-check"></i><b>2.7</b> Eigenvectors</a></li>
<li class="chapter" data-level="2.8" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#variance"><i class="fa fa-check"></i><b>2.8</b> Variance</a></li>
<li class="chapter" data-level="2.9" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#covariance"><i class="fa fa-check"></i><b>2.9</b> Covariance</a></li>
<li class="chapter" data-level="2.10" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#references"><i class="fa fa-check"></i><b>2.10</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html"><i class="fa fa-check"></i><b>3</b> Glossary 2 (PCA)</a><ul>
<li class="chapter" data-level="3.1" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html#cloud-of-variables"><i class="fa fa-check"></i><b>3.1</b> Cloud of variables</a></li>
<li class="chapter" data-level="3.2" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html#cloud-of-individuals"><i class="fa fa-check"></i><b>3.2</b> Cloud of individuals</a></li>
<li class="chapter" data-level="3.3" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html#principal-component"><i class="fa fa-check"></i><b>3.3</b> Principal Component</a></li>
<li class="chapter" data-level="3.4" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html#active-variables"><i class="fa fa-check"></i><b>3.4</b> Active variables</a></li>
<li class="chapter" data-level="3.5" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html#supplementary-variables"><i class="fa fa-check"></i><b>3.5</b> Supplementary variables</a></li>
<li class="chapter" data-level="3.6" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html#eigenvalues-interpretation-in-factor-analysis-and-principal-component-analysis"><i class="fa fa-check"></i><b>3.6</b> Eigenvalues (interpretation in Factor Analysis and Principal Component Analysis)</a></li>
<li class="chapter" data-level="3.7" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html#rotation"><i class="fa fa-check"></i><b>3.7</b> Rotation</a></li>
<li class="chapter" data-level="3.8" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html#screeplot"><i class="fa fa-check"></i><b>3.8</b> Screeplot</a></li>
<li class="chapter" data-level="3.9" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html#references-1"><i class="fa fa-check"></i><b>3.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="glossary-3-factor-analysis.html"><a href="glossary-3-factor-analysis.html"><i class="fa fa-check"></i><b>4</b> Glossary 3 (Factor Analysis)</a><ul>
<li class="chapter" data-level="4.1" data-path="glossary-3-factor-analysis.html"><a href="glossary-3-factor-analysis.html#factor"><i class="fa fa-check"></i><b>4.1</b> Factor</a></li>
<li class="chapter" data-level="4.2" data-path="glossary-3-factor-analysis.html"><a href="glossary-3-factor-analysis.html#communalities"><i class="fa fa-check"></i><b>4.2</b> Communalities</a></li>
<li class="chapter" data-level="4.3" data-path="glossary-3-factor-analysis.html"><a href="glossary-3-factor-analysis.html#factor-loadings"><i class="fa fa-check"></i><b>4.3</b> Factor loadings</a></li>
<li class="chapter" data-level="4.4" data-path="glossary-3-factor-analysis.html"><a href="glossary-3-factor-analysis.html#factor-values-factor-scores"><i class="fa fa-check"></i><b>4.4</b> Factor values (Factor scores)</a></li>
<li class="chapter" data-level="4.5" data-path="glossary-3-factor-analysis.html"><a href="glossary-3-factor-analysis.html#anti-image-correlation-matrix"><i class="fa fa-check"></i><b>4.5</b> Anti-image correlation matrix</a></li>
<li class="chapter" data-level="4.6" data-path="glossary-3-factor-analysis.html"><a href="glossary-3-factor-analysis.html#kaiser-meyer-olkin-criterion-kmo"><i class="fa fa-check"></i><b>4.6</b> Kaiser-Meyer-Olkin criterion (KMO)</a></li>
<li class="chapter" data-level="4.7" data-path="glossary-3-factor-analysis.html"><a href="glossary-3-factor-analysis.html#measure-of-sampling-adequacy-msa"><i class="fa fa-check"></i><b>4.7</b> Measure of Sampling Adequacy (MSA)</a></li>
<li class="chapter" data-level="4.8" data-path="glossary-3-factor-analysis.html"><a href="glossary-3-factor-analysis.html#references-2"><i class="fa fa-check"></i><b>4.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html"><i class="fa fa-check"></i><b>5</b> Glossary 4 (MCA, CA)</a><ul>
<li class="chapter" data-level="5.1" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#multiple-correspondence-analysis-vs-correspondence-analysis"><i class="fa fa-check"></i><b>5.1</b> Multiple Correspondence Analysis vs Correspondence Analysis</a></li>
<li class="chapter" data-level="5.2" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#cloud-of-individuals-in-mca"><i class="fa fa-check"></i><b>5.2</b> Cloud of individuals in MCA</a></li>
<li class="chapter" data-level="5.3" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#cloud-of-categories-in-mca"><i class="fa fa-check"></i><b>5.3</b> Cloud of categories in MCA</a></li>
<li class="chapter" data-level="5.4" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#proﬁle"><i class="fa fa-check"></i><b>5.4</b> Proﬁle</a></li>
<li class="chapter" data-level="5.5" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#weight"><i class="fa fa-check"></i><b>5.5</b> Weight</a></li>
<li class="chapter" data-level="5.6" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#inertia"><i class="fa fa-check"></i><b>5.6</b> Inertia</a></li>
<li class="chapter" data-level="5.7" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#chi-square-distance"><i class="fa fa-check"></i><b>5.7</b> Chi-Square-Distance</a></li>
<li class="chapter" data-level="5.8" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#contribution"><i class="fa fa-check"></i><b>5.8</b> Contribution</a></li>
<li class="chapter" data-level="5.9" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#supplementary-variablesindividuals-in-camca"><i class="fa fa-check"></i><b>5.9</b> Supplementary variables/individuals in CA/MCA</a></li>
<li class="chapter" data-level="5.10" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#concentration-ellipse"><i class="fa fa-check"></i><b>5.10</b> Concentration ellipse</a></li>
<li class="chapter" data-level="5.11" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#confidence-ellipse"><i class="fa fa-check"></i><b>5.11</b> Confidence ellipse</a></li>
<li class="chapter" data-level="5.12" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#binary-indicator-matrix"><i class="fa fa-check"></i><b>5.12</b> Binary indicator matrix</a></li>
<li class="chapter" data-level="5.13" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#burt-matrix"><i class="fa fa-check"></i><b>5.13</b> Burt matrix</a></li>
<li class="chapter" data-level="5.14" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#references-3"><i class="fa fa-check"></i><b>5.14</b> References</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="glossary-5-cluster-analysis.html"><a href="glossary-5-cluster-analysis.html"><i class="fa fa-check"></i><b>6</b> Glossary 5 (Cluster Analysis)</a><ul>
<li class="chapter" data-level="6.1" data-path="glossary-5-cluster-analysis.html"><a href="glossary-5-cluster-analysis.html#euclidean-distance"><i class="fa fa-check"></i><b>6.1</b> Euclidean distance</a></li>
<li class="chapter" data-level="6.2" data-path="glossary-5-cluster-analysis.html"><a href="glossary-5-cluster-analysis.html#manhattan-distance"><i class="fa fa-check"></i><b>6.2</b> Manhattan distance</a></li>
<li class="chapter" data-level="6.3" data-path="glossary-5-cluster-analysis.html"><a href="glossary-5-cluster-analysis.html#mahalanobis-distance"><i class="fa fa-check"></i><b>6.3</b> Mahalanobis distance</a></li>
<li class="chapter" data-level="6.4" data-path="glossary-5-cluster-analysis.html"><a href="glossary-5-cluster-analysis.html#hierarchical-clustering"><i class="fa fa-check"></i><b>6.4</b> Hierarchical clustering</a></li>
<li class="chapter" data-level="6.5" data-path="glossary-5-cluster-analysis.html"><a href="glossary-5-cluster-analysis.html#partitioning"><i class="fa fa-check"></i><b>6.5</b> Partitioning</a></li>
<li class="chapter" data-level="6.6" data-path="glossary-5-cluster-analysis.html"><a href="glossary-5-cluster-analysis.html#dendrogram"><i class="fa fa-check"></i><b>6.6</b> Dendrogram</a></li>
<li class="chapter" data-level="6.7" data-path="glossary-5-cluster-analysis.html"><a href="glossary-5-cluster-analysis.html#references-4"><i class="fa fa-check"></i><b>6.7</b> References</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Final Glossary Bookdown</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="glossary-3-factor-analysis" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Glossary 3 (Factor Analysis)</h1>
<div id="factor" class="section level2">
<h2><span class="header-section-number">4.1</span> Factor</h2>
<p>Factor is a classified element from which it is being a cause in general, in factor analysis, factor means the underlying variables which is smaller than the observed variables, explains how those observed variables are interrelated each other.
Factor analysis is aiming to model the interrelationships among items which is explained by the found factors. The relation between observed variables and factors are shown in following image.</p>
<div class="figure">
<img src="Factor.png" alt="© van den Berg" style="width:40.0%" />
<p class="caption">© van den Berg</p>
</div>
</div>
<div id="communalities" class="section level2">
<h2><span class="header-section-number">4.2</span> Communalities</h2>
<p>Communality describes a common variance which ranges between 0 and 1 in factor analysis, symbol of communality is shown as h^2 (see the notation below). The common variance is the shared variance among the items, as more these items are strongly related from each other, shared variance gets larger. Communalities give how well the model performs, if communality is closer to 1, it means that the extracted factors by the analysis explain more variance of an item. In that case, the model explains better. The total variance in factor analysis is consisted from common variance and unique variance which is composed of specific(S) and error(E) variance (see image below).The individual communarities tell how it is explained for individual variables, overall communarities gives an overall assessment of the performance.</p>
<p><span class="math display">\[
\hat{h}_i^2 = {\sum_{j=1}^m} \hat{l}_{ij}^2
\]</span></p>
<div class="figure">
<img src="Communality.png" alt="© UCLA." style="width:40.0%" />
<p class="caption">© UCLA.</p>
</div>
<p>In comparison, in PCA, the communality is the sum of extracted proportion of variance of selected components.In PCA, unique variance is not taken into account. Thus, if the communalities across all items are summed up, it is equal to total variance. The sum of eigenvalues of each component is also equal to the total variance, therefore, those communalities and eigenvalues are equal in PCA.
When the total variance is 1, then common variance = communality.</p>
</div>
<div id="factor-loadings" class="section level2">
<h2><span class="header-section-number">4.3</span> Factor loadings</h2>
<p>Factor loadings are the correlation coefficients between the variables and factors in factor analysis and PCA. It shows how much the variance in the variable is explained by the factor. Loadings can be between -1 to 1, close to -1 and 1 means that the factor influences strongly towards the variable, close to 0 means the influence is weak.
If a variable has more than one significant factor loadings, it is called as cross loadings which is hard to interpret. In this case, rotation of factor loadings is proceeded, so that the factor loadings are redistributed as each variable measures only one factor.
Following example shows the solution of factor loadings of data “Thurstone” between factors (RC1-RC3) and variables which are indicating the ability items.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="kw">data</span>(Thurstone)</a>
<a class="sourceLine" id="cb7-2" data-line-number="2">fa3 &lt;-<span class="st"> </span><span class="kw">principal</span>(<span class="dt">r =</span> Thurstone,</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">  <span class="dt">nfactors =</span> <span class="dv">3</span>,</a>
<a class="sourceLine" id="cb7-4" data-line-number="4">  <span class="dt">n.obs =</span> <span class="dv">213</span>)</a>
<a class="sourceLine" id="cb7-5" data-line-number="5"><span class="kw">print</span>(fa3<span class="op">$</span>loadings, <span class="dt">cutoff=</span><span class="dv">0</span>, <span class="dt">digits=</span><span class="dv">3</span>)</a></code></pre></div>
<pre><code>## 
## Loadings:
##                   RC1   RC2   RC3  
## Sentences         0.863 0.243 0.229
## Vocabulary        0.854 0.314 0.189
## Sent.Completion   0.849 0.262 0.189
## First.Letters     0.226 0.823 0.231
## Four.Letter.Words 0.183 0.791 0.301
## Suffixes          0.314 0.773 0.057
## Letter.Series     0.249 0.158 0.834
## Pedigrees         0.534 0.080 0.613
## Letter.Group      0.095 0.311 0.805
## 
##                  RC1   RC2   RC3
## SS loadings    2.735 2.254 1.990
## Proportion Var 0.304 0.250 0.221
## Cumulative Var 0.304 0.554 0.775</code></pre>
</div>
<div id="factor-values-factor-scores" class="section level2">
<h2><span class="header-section-number">4.4</span> Factor values (Factor scores)</h2>
<p>When factor loadings are low, or looks very different from each other, it is possible to create an index which reflects the inequality of association between items and the factor, which are the factor scores. Factor scores are the estimated values of factors, optimally weighted linear combination of the items, creating the index variable. Each item’s weight is derived from its factor loading, thus, each item’s contribution to the factor score depends on how strongly it relates to the factor. The reason why factor scores are essentially weighted sum of the items is that those weights are between -1 to 1, the scale of the factor scores would be varied from a pure sum.</p>
</div>
<div id="anti-image-correlation-matrix" class="section level2">
<h2><span class="header-section-number">4.5</span> Anti-image correlation matrix</h2>
<p>Anti-image is a part of variable which cannot be predicted, since the image of a variable is defined as a part which is predictable by regressing each variables. Anti-image correlation matrix indicates how the items are correlated in the matrix, it summarizes the most important information about partial correlations. Thus, helping to indicate the part of variables which is not predictable. The diagonal values are the KMO(explained later) measures of sampling adequacy, the off-diagonal values are showing the negative of the pairwise partial correlation coefficients. Most of the off-diagonal elements should be small so that the factor analysis model can be considered as having better goodness.
Following figure is showing the example from the data of “Thurstone”.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="kw">cor</span>(Thurstone, <span class="dt">use=</span><span class="st">&quot;pairwise&quot;</span>)</a></code></pre></div>
<pre><code>##                    Sentences  Vocabulary Sent.Completion First.Letters
## Sentences          1.0000000  0.91636022      0.86759906    -0.3041112
## Vocabulary         0.9163602  1.00000000      0.86863779    -0.1784238
## Sent.Completion    0.8675991  0.86863779      1.00000000    -0.2315780
## First.Letters     -0.3041112 -0.17842378     -0.23157804     1.0000000
## Four.Letter.Words -0.3652704 -0.27790681     -0.33725544     0.6607587
## Suffixes          -0.1322282 -0.02188666     -0.09780351     0.4881992
## Letter.Series     -0.2355010 -0.32712116     -0.32540886    -0.4848485
## Pedigrees          0.2202801  0.15769908      0.19825849    -0.6161762
## Letter.Group      -0.4856669 -0.57378661     -0.52569295    -0.2543441
##                   Four.Letter.Words    Suffixes Letter.Series   Pedigrees
## Sentences                -0.3652704 -0.13222821    -0.2355010  0.22028010
## Vocabulary               -0.2779068 -0.02188666    -0.3271212  0.15769908
## Sent.Completion          -0.3372554 -0.09780351    -0.3254089  0.19825849
## First.Letters             0.6607587  0.48819920    -0.4848485 -0.61617617
## Four.Letter.Words         1.0000000  0.35087898    -0.3811472 -0.55819512
## Suffixes                  0.3508790  1.00000000    -0.6777077 -0.58649627
## Letter.Series            -0.3811472 -0.67770771     1.0000000  0.32820549
## Pedigrees                -0.5581951 -0.58649627     0.3282055  1.00000000
## Letter.Group             -0.1476621 -0.49914387     0.5042140 -0.01395292
##                   Letter.Group
## Sentences          -0.48566690
## Vocabulary         -0.57378661
## Sent.Completion    -0.52569295
## First.Letters      -0.25434412
## Four.Letter.Words  -0.14766210
## Suffixes           -0.49914387
## Letter.Series       0.50421396
## Pedigrees          -0.01395292
## Letter.Group        1.00000000</code></pre>
</div>
<div id="kaiser-meyer-olkin-criterion-kmo" class="section level2">
<h2><span class="header-section-number">4.6</span> Kaiser-Meyer-Olkin criterion (KMO)</h2>
<p>Kaiser-Meyer-Olkin criterion (KMO) is a modified version of the Measure of Sampling Adequacy (MSA, will be explained below), by Kaiser and Rice (1974). It indicates the degree of each variables in a dataset can be predicted without error which caused by other variables. This analysis is relying on anti-image correlation matrix, measured by 0 to 1, value 0 means that the sum of partial correlation is large compared to the sum of correlations which means the correlations are wide spread, this is indicating the factor analysis is not likely be appropriate. Thus, if the value is closer to 1, the dataset is considered as suitable for factor analysis.
Mathematical notation is as follows.
<span class="math display">\[
KMO =  \frac {\sum_{i=1}^k \sum_{j=1}^k r_{ij}^2} {\sum_{i=1}^k \sum_{j=1}^k r_{ij}^2 + a_{ij}^2} ,   i\ne j
\]</span></p>
</div>
<div id="measure-of-sampling-adequacy-msa" class="section level2">
<h2><span class="header-section-number">4.7</span> Measure of Sampling Adequacy (MSA)</h2>
<p>Measure of Sampling Adequacy (MSA) is introduced by Kaiser(1970) before he modified Kaiser Meyer-Olkin criterion. This is a statistical value used as an index for deciding if the sample is suitable for performing factor analysis or not. It calculates the measure of 0 to 1, as the result is closer to 1, it is better, 0.6 is the suggested minimum. It is mentioned that MSA increases 1)when the number of variables increases, 2)when the effective number of factors increases, 3)when the overall level of correlation increases, and 4)when sample size of individuals increases.
Mathematical notation is as follows.</p>
<p><span class="math display">\[
MSA_i =  \frac {\sum_{j=1}^k r_{ij}^2} {\sum_{j=1}^k r_{ij}^2 + a_{ij}^2} ,   j \ne i
\]</span></p>
<p>Given these explanation, KMO has been applied to the data of “Thurstone”.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="kw">KMO</span>(Thurstone)</a></code></pre></div>
<pre><code>## Kaiser-Meyer-Olkin factor adequacy
## Call: KMO(r = Thurstone)
## Overall MSA =  0.88
## MSA for each item = 
##         Sentences        Vocabulary   Sent.Completion     First.Letters 
##              0.86              0.86              0.90              0.86 
## Four.Letter.Words          Suffixes     Letter.Series         Pedigrees 
##              0.88              0.92              0.85              0.93 
##      Letter.Group 
##              0.87</code></pre>
<p>Considering the value, overall value and all of values for each item are higher than 0.6, very close to 1, it can be assumed that the data is suitable for factor analysis.</p>
</div>
<div id="references-2" class="section level2">
<h2><span class="header-section-number">4.8</span> References</h2>
<p>Cerny.B.A. and Kaiser.H.F.(2010). A Study Of A Measure Of Sampling Adequacy For Factor-Analytic Correlation Matrices. Taylor &amp; Francis Online. [online].Retrieved from <a href="https://www.tandfonline.com/doi/abs/10.1207/s15327906mbr1201_3" class="uri">https://www.tandfonline.com/doi/abs/10.1207/s15327906mbr1201_3</a> [accessed on 15.06.2020].</p>
<p>Lüdecke.D., Makowski.D.and Mattan.S.B.S. Kaiser, Meyer, Olkin (KMO) Measure of Sampling Adequacy (MSA) for Factor Analysis.[online].Retrieved from <a href="https://easystats.github.io/parameters/reference/check_kmo.html" class="uri">https://easystats.github.io/parameters/reference/check_kmo.html</a> [accessed on 15.06.2020].</p>
<p>Le Roux.B.and Rouanet.H. (2004). Geometric Data Analysis. Kluwer Academic Publishers.</p>
<p>PennEtate Eberly College of Science. (2020).12.5 - Communalities. The Pennsylvania State University. [online]. Retrieved from <a href="https://online.stat.psu.edu/stat505/lesson/12/12.5" class="uri">https://online.stat.psu.edu/stat505/lesson/12/12.5</a> [accessed on 16.06.2020].</p>
<p>Quicl.J. M. (2014). R Tutorial Series. [online].Retrieved from <a href="http://rtutorialseries.blogspot.com/2011/10/r-tutorial-series-exploratory-factor.html" class="uri">http://rtutorialseries.blogspot.com/2011/10/r-tutorial-series-exploratory-factor.html</a> [accessed on 15.06.2020].</p>
<p>Revelle. W.(2019). How To: Use the psych package for Factor Analysis and data reduction. Department of Psychology
Northwestern University. [online]. Retrieved from <a href="http://personality-project.org/r/psych/HowTo/factor.pdf" class="uri">http://personality-project.org/r/psych/HowTo/factor.pdf</a> [accessed on 15.06.2020]</p>
<p>Revelle. W.(2020). Package ‘psych’. CRAN.[online].Retrieved from <a href="https://cran.r-project.org/web/packages/psych/psych.pdf" class="uri">https://cran.r-project.org/web/packages/psych/psych.pdf</a> [accessed on 15.06.2020]</p>
<p>Stata. (2020). Glossary Factor analysis. Stata.[online].Retrieved from <a href="https://www.stata.com/manuals13/mvglossary.pdf" class="uri">https://www.stata.com/manuals13/mvglossary.pdf</a> [accessed on 15.06.2020]</p>
<p>UCLA.(2020). A Practical Introduction to Factor Analysis: Exploratory Factor Analysis.UCLA Statistical Consulting.[online].Retrieved from <a href="https://stats.idre.ucla.edu/spss/seminars/introduction-to-factor-analysis/a-practical-introduction-to-factor-analysis/" class="uri">https://stats.idre.ucla.edu/spss/seminars/introduction-to-factor-analysis/a-practical-introduction-to-factor-analysis/</a> [accessed on 15.06.2020].</p>
<p>Van den Berg.R.G. (2020). SPSS Factor Analysis – Beginners Tutorial. SPSS Tutorials.[online].Retrieved from <a href="https://www.spss-tutorials.com/spss-factor-analysis-tutorial/" class="uri">https://www.spss-tutorials.com/spss-factor-analysis-tutorial/</a> [accessed on 15.06.2020].</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="glossary-2-pca.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="glossary-4-mca-ca.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Bookdown-MarinaObata2.pdf", "Bookdown-MarinaObata2.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
