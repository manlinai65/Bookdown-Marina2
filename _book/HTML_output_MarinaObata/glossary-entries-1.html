<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Glossary entries | Final Glossary Bookdown</title>
  <meta name="description" content="Final Glossary" />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Glossary entries | Final Glossary Bookdown" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Final Glossary" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Glossary entries | Final Glossary Bookdown" />
  
  <meta name="twitter:description" content="Final Glossary" />
  

<meta name="author" content="Marina Obata" />


<meta name="date" content="2020-06-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="glossary-2-pca.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Marina Obata final glossary</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Index for final Glossary</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#glossary-entries"><i class="fa fa-check"></i><b>1.1</b> 1.Glossary entries</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#glossary--pca-"><i class="fa fa-check"></i><b>1.2</b> 2.Glossary -PCA-</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#glossary--factor-analysis-"><i class="fa fa-check"></i><b>1.3</b> 3.Glossary -Factor Analysis-</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#glossary--mcaca-"><i class="fa fa-check"></i><b>1.4</b> 4.Glossary -MCA,CA-</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#glossary--cluster-analysis-"><i class="fa fa-check"></i><b>1.5</b> 5.Glossary -Cluster analysis-</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html"><i class="fa fa-check"></i><b>2</b> Glossary entries</a><ul>
<li class="chapter" data-level="2.1" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#exploratory-data-analysis-eda"><i class="fa fa-check"></i><b>2.1</b> Exploratory Data Analysis (EDA)</a></li>
<li class="chapter" data-level="2.2" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#principal-component-analysis-pca"><i class="fa fa-check"></i><b>2.2</b> Principal Component Analysis (PCA)</a></li>
<li class="chapter" data-level="2.3" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#factor-analysis"><i class="fa fa-check"></i><b>2.3</b> Factor Analysis</a></li>
<li class="chapter" data-level="2.4" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#cluster-analysis"><i class="fa fa-check"></i><b>2.4</b> Cluster Analysis</a></li>
<li class="chapter" data-level="2.5" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#correspondence-analysis-ca"><i class="fa fa-check"></i><b>2.5</b> Correspondence Analysis (CA)</a></li>
<li class="chapter" data-level="2.6" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#eigenvalues"><i class="fa fa-check"></i><b>2.6</b> Eigenvalues</a></li>
<li class="chapter" data-level="2.7" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#eigenvectors"><i class="fa fa-check"></i><b>2.7</b> Eigenvectors</a></li>
<li class="chapter" data-level="2.8" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#variance"><i class="fa fa-check"></i><b>2.8</b> Variance</a></li>
<li class="chapter" data-level="2.9" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#covariance"><i class="fa fa-check"></i><b>2.9</b> Covariance</a></li>
<li class="chapter" data-level="2.10" data-path="glossary-entries-1.html"><a href="glossary-entries-1.html#references"><i class="fa fa-check"></i><b>2.10</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html"><i class="fa fa-check"></i><b>3</b> Glossary 2 (PCA)</a><ul>
<li class="chapter" data-level="3.1" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html#cloud-of-variables"><i class="fa fa-check"></i><b>3.1</b> Cloud of variables</a></li>
<li class="chapter" data-level="3.2" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html#cloud-of-individuals"><i class="fa fa-check"></i><b>3.2</b> Cloud of individuals</a></li>
<li class="chapter" data-level="3.3" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html#principal-component"><i class="fa fa-check"></i><b>3.3</b> Principal Component</a></li>
<li class="chapter" data-level="3.4" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html#active-variables"><i class="fa fa-check"></i><b>3.4</b> Active variables</a></li>
<li class="chapter" data-level="3.5" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html#supplementary-variables"><i class="fa fa-check"></i><b>3.5</b> Supplementary variables</a></li>
<li class="chapter" data-level="3.6" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html#eigenvalues-interpretation-in-factor-analysis-and-principal-component-analysis"><i class="fa fa-check"></i><b>3.6</b> Eigenvalues (interpretation in Factor Analysis and Principal Component Analysis)</a></li>
<li class="chapter" data-level="3.7" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html#rotation"><i class="fa fa-check"></i><b>3.7</b> Rotation</a></li>
<li class="chapter" data-level="3.8" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html#screeplot"><i class="fa fa-check"></i><b>3.8</b> Screeplot</a></li>
<li class="chapter" data-level="3.9" data-path="glossary-2-pca.html"><a href="glossary-2-pca.html#references-1"><i class="fa fa-check"></i><b>3.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="glossary-3-factor-analysis.html"><a href="glossary-3-factor-analysis.html"><i class="fa fa-check"></i><b>4</b> Glossary 3 (Factor Analysis)</a><ul>
<li class="chapter" data-level="4.1" data-path="glossary-3-factor-analysis.html"><a href="glossary-3-factor-analysis.html#factor"><i class="fa fa-check"></i><b>4.1</b> Factor</a></li>
<li class="chapter" data-level="4.2" data-path="glossary-3-factor-analysis.html"><a href="glossary-3-factor-analysis.html#communalities"><i class="fa fa-check"></i><b>4.2</b> Communalities</a></li>
<li class="chapter" data-level="4.3" data-path="glossary-3-factor-analysis.html"><a href="glossary-3-factor-analysis.html#factor-loadings"><i class="fa fa-check"></i><b>4.3</b> Factor loadings</a></li>
<li class="chapter" data-level="4.4" data-path="glossary-3-factor-analysis.html"><a href="glossary-3-factor-analysis.html#factor-values-factor-scores"><i class="fa fa-check"></i><b>4.4</b> Factor values (Factor scores)</a></li>
<li class="chapter" data-level="4.5" data-path="glossary-3-factor-analysis.html"><a href="glossary-3-factor-analysis.html#anti-image-correlation-matrix"><i class="fa fa-check"></i><b>4.5</b> Anti-image correlation matrix</a></li>
<li class="chapter" data-level="4.6" data-path="glossary-3-factor-analysis.html"><a href="glossary-3-factor-analysis.html#kaiser-meyer-olkin-criterion-kmo"><i class="fa fa-check"></i><b>4.6</b> Kaiser-Meyer-Olkin criterion (KMO)</a></li>
<li class="chapter" data-level="4.7" data-path="glossary-3-factor-analysis.html"><a href="glossary-3-factor-analysis.html#measure-of-sampling-adequacy-msa"><i class="fa fa-check"></i><b>4.7</b> Measure of Sampling Adequacy (MSA)</a></li>
<li class="chapter" data-level="4.8" data-path="glossary-3-factor-analysis.html"><a href="glossary-3-factor-analysis.html#references-2"><i class="fa fa-check"></i><b>4.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html"><i class="fa fa-check"></i><b>5</b> Glossary 4 (MCA, CA)</a><ul>
<li class="chapter" data-level="5.1" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#multiple-correspondence-analysis-vs-correspondence-analysis"><i class="fa fa-check"></i><b>5.1</b> Multiple Correspondence Analysis vs Correspondence Analysis</a></li>
<li class="chapter" data-level="5.2" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#cloud-of-individuals-in-mca"><i class="fa fa-check"></i><b>5.2</b> Cloud of individuals in MCA</a></li>
<li class="chapter" data-level="5.3" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#cloud-of-categories-in-mca"><i class="fa fa-check"></i><b>5.3</b> Cloud of categories in MCA</a></li>
<li class="chapter" data-level="5.4" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#proﬁle"><i class="fa fa-check"></i><b>5.4</b> Proﬁle</a></li>
<li class="chapter" data-level="5.5" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#weight"><i class="fa fa-check"></i><b>5.5</b> Weight</a></li>
<li class="chapter" data-level="5.6" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#inertia"><i class="fa fa-check"></i><b>5.6</b> Inertia</a></li>
<li class="chapter" data-level="5.7" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#chi-square-distance"><i class="fa fa-check"></i><b>5.7</b> Chi-Square-Distance</a></li>
<li class="chapter" data-level="5.8" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#contribution"><i class="fa fa-check"></i><b>5.8</b> Contribution</a></li>
<li class="chapter" data-level="5.9" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#supplementary-variablesindividuals-in-camca"><i class="fa fa-check"></i><b>5.9</b> Supplementary variables/individuals in CA/MCA</a></li>
<li class="chapter" data-level="5.10" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#concentration-ellipse"><i class="fa fa-check"></i><b>5.10</b> Concentration ellipse</a></li>
<li class="chapter" data-level="5.11" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#confidence-ellipse"><i class="fa fa-check"></i><b>5.11</b> Confidence ellipse</a></li>
<li class="chapter" data-level="5.12" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#binary-indicator-matrix"><i class="fa fa-check"></i><b>5.12</b> Binary indicator matrix</a></li>
<li class="chapter" data-level="5.13" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#burt-matrix"><i class="fa fa-check"></i><b>5.13</b> Burt matrix</a></li>
<li class="chapter" data-level="5.14" data-path="glossary-4-mca-ca.html"><a href="glossary-4-mca-ca.html#references-3"><i class="fa fa-check"></i><b>5.14</b> References</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="glossary-5-cluster-analysis.html"><a href="glossary-5-cluster-analysis.html"><i class="fa fa-check"></i><b>6</b> Glossary 5 (Cluster Analysis)</a><ul>
<li class="chapter" data-level="6.1" data-path="glossary-5-cluster-analysis.html"><a href="glossary-5-cluster-analysis.html#euclidean-distance"><i class="fa fa-check"></i><b>6.1</b> Euclidean distance</a></li>
<li class="chapter" data-level="6.2" data-path="glossary-5-cluster-analysis.html"><a href="glossary-5-cluster-analysis.html#manhattan-distance"><i class="fa fa-check"></i><b>6.2</b> Manhattan distance</a></li>
<li class="chapter" data-level="6.3" data-path="glossary-5-cluster-analysis.html"><a href="glossary-5-cluster-analysis.html#mahalanobis-distance"><i class="fa fa-check"></i><b>6.3</b> Mahalanobis distance</a></li>
<li class="chapter" data-level="6.4" data-path="glossary-5-cluster-analysis.html"><a href="glossary-5-cluster-analysis.html#hierarchical-clustering"><i class="fa fa-check"></i><b>6.4</b> Hierarchical clustering</a></li>
<li class="chapter" data-level="6.5" data-path="glossary-5-cluster-analysis.html"><a href="glossary-5-cluster-analysis.html#partitioning"><i class="fa fa-check"></i><b>6.5</b> Partitioning</a></li>
<li class="chapter" data-level="6.6" data-path="glossary-5-cluster-analysis.html"><a href="glossary-5-cluster-analysis.html#dendrogram"><i class="fa fa-check"></i><b>6.6</b> Dendrogram</a></li>
<li class="chapter" data-level="6.7" data-path="glossary-5-cluster-analysis.html"><a href="glossary-5-cluster-analysis.html#references-4"><i class="fa fa-check"></i><b>6.7</b> References</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Final Glossary Bookdown</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="glossary-entries-1" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Glossary entries</h1>
<div id="exploratory-data-analysis-eda" class="section level2">
<h2><span class="header-section-number">2.1</span> Exploratory Data Analysis (EDA)</h2>
<p>It is a concept that getting familiar with the data from the blank white paper.
By doing so, it enables to build assumptions regarding the operationalization of data and check the quality of the data. As a process, firstly, generate questions about the data, secondly, search for answers by using main tools of EDA such as visualization, transformation and modelling. Then, use what is learned to refine the questions and generate new questions.
The goal during EDA is to develop an understanding of the data.</p>
</div>
<div id="principal-component-analysis-pca" class="section level2">
<h2><span class="header-section-number">2.2</span> Principal Component Analysis (PCA)</h2>
<p>In order to interpret the increasingly widespread large datasets, methods which reduce the dimensionality of the datasets in an interpretable way are required. Principal component analysis(PCA) is one of the oldest and most widely used method.
PCA is used to extract the information from a multivariate dataset to express the dataset as a set of few new variables called principal components, which corresponds to a linear combination of the original dataset. PCA assumes that the directions with the largest variances are the most important. The goal of PCA is to identify the principal components along which the variation in the data is maximal.
It is mostly used in the field of explanatory studies to make predictive models.<br />
In plot 1A, PC1 axis is the first principal direction which the samples show the largest variations, PC2 axis is the second most important direction. It can be reduced to a two-dimension plot by projecting PC1 and PC2 on the first principal component shown in Plot 1B.</p>
<div class="figure">
<img src="PCA_intro.png" alt="© Kassambara, 2017" style="width:60.0%" />
<p class="caption">© Kassambara, 2017</p>
</div>
</div>
<div id="factor-analysis" class="section level2">
<h2><span class="header-section-number">2.3</span> Factor Analysis</h2>
<p>Prior to PCA which has only become possible at the computer age, a related method was factor analysis, which was extensively applied to psychometric data. The aim of factor analysis is to summarize a set of variables by a smaller number of variables which helps in data interpretation. It is a linear statistical model, used to explain the variance among the observed variable and condense a set of the observed variable into the unobserved variable which is called factors (see the figure below). Factor analysis is on variables, not on individuals.</p>
<div class="figure">
<img src="Factoranalysis.png" alt="© Navlani, 2019" style="width:50.0%" />
<p class="caption">© Navlani, 2019</p>
</div>
</div>
<div id="cluster-analysis" class="section level2">
<h2><span class="header-section-number">2.4</span> Cluster Analysis</h2>
<p>Cluster analysis is similar as PCA, one of the important methods for discovering knowledge in multidimensional data but differs since cluster analysis goes further to specify the characteristics of each sub-groups according to a defined distance measure.
Cluster analysis is applied in various fields of marketing, retail, medical science, sociology and so on.
The goal of clustering is to identify pattern or groups of similar objects within a dataset.
Following figure shows an example of cluster analysis of the states in the U.S. regarding arrested records.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">data</span>(<span class="st">&quot;USArrests&quot;</span>)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2">df_a &lt;-<span class="st"> </span><span class="kw">scale</span>(USArrests)</a>
<a class="sourceLine" id="cb1-3" data-line-number="3">res.km &lt;-<span class="st"> </span><span class="kw">eclust</span>(df_a, <span class="st">&quot;kmeans&quot;</span>, <span class="dt">nstart =</span> <span class="dv">25</span>)</a></code></pre></div>
<p><img src="Bookdown-MarinaObata2_files/figure-html/1-2-1.png" width="60%" /></p>
</div>
<div id="correspondence-analysis-ca" class="section level2">
<h2><span class="header-section-number">2.5</span> Correspondence Analysis (CA)</h2>
<p>Correspondence analysis is the leading case of Geometric Data Analysis. CA is similar with PCA in the aspect of providing a solution for summarizing and visualizing data set into two-dimension plots, at the same time, as an extension of PCA, suited to explore among categorical data. CA is a geometric approach for visualizing the rows and columns of a two-way contingency table, in which positions of the row and column points are consistent with their association in the visualization. The goal of CA is to have a global view of the data that is useful for interpretation.
Following contingency table shows the data regarding division of housetasks in the couple, following graph visualizes the CA in the function of biplot, rows are represented by blue points and columns by red triangles.</p>
<div class="figure">
<img src="housework.png" alt="© Kassambara, 2017" style="width:55.0%" />
<p class="caption">© Kassambara, 2017</p>
</div>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="kw">data</span>(housetasks)</a>
<a class="sourceLine" id="cb2-2" data-line-number="2">dt &lt;-<span class="st"> </span><span class="kw">as.table</span>(<span class="kw">as.matrix</span>(housetasks))</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">res.ca &lt;-<span class="st"> </span><span class="kw">CA</span>(housetasks, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb2-4" data-line-number="4"><span class="kw">fviz_ca_biplot</span>(res.ca, <span class="dt">repel =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<p><img src="Bookdown-MarinaObata2_files/figure-html/1-3-1.png" width="60%" /></p>
</div>
<div id="eigenvalues" class="section level2">
<h2><span class="header-section-number">2.6</span> Eigenvalues</h2>
<p>Eigenvalues are the values which won’t be changed even the surface of the vector got moved in different directions. In PCA, eigenvalues measure the amount of variation retained by each principle component, in CA, eigenvalues correspond to the amount of information retained by each axis. Also, eigenvalues can be used to determine number of principal components/axis to be considered. In factor analysis, an eigenvalue is a measure of how much of the variance of the observed variables a factor explains.
The mathematics of eigenvalue is shown as following formula.</p>
<div class="figure">
<img src="eigenvalue.png" alt="© MathsisFun, 2019" style="width:50.0%" />
<p class="caption">© MathsisFun, 2019</p>
</div>
</div>
<div id="eigenvectors" class="section level2">
<h2><span class="header-section-number">2.7</span> Eigenvectors</h2>
<p>Eigenvectors are the vectors which won’t change the directions even the surface of the vector got changed. Each eigenvector has a corresponding eigenvalue, if eigenvectors are sorted in descending order with respect to their eigen values, we will have the first eigenvector accounts for the largest spread among data, the second one for the second largest spread and so on.
In following example, the direction in green is the eigenvector, it has a corresponding eigenvalue which describes its magnitude.</p>
<div class="figure">
<img src="eigens.png" alt="© Alto, 2019" style="width:50.0%" />
<p class="caption">© Alto, 2019</p>
</div>
</div>
<div id="variance" class="section level2">
<h2><span class="header-section-number">2.8</span> Variance</h2>
<p>Variance shows how the group of the numbers are spreading around from its average.
If the variance has a large number, it means there is a large variation in numerical values within a group of the data. In PCA and CA, the large value of variance shows the importance, which means variance is showing the amount of information. Dimensions are ordered and listed accordingly to the amount of variance, dimension 1 explains the most variance, followed by dimension 2 and so on. Also, it is corresponding with the eigenvalue (see the table below.)</p>
<div class="figure">
<img src="eigenvariance.png" alt="© Kassambara, 2017" style="width:70.0%" />
<p class="caption">© Kassambara, 2017</p>
</div>
</div>
<div id="covariance" class="section level2">
<h2><span class="header-section-number">2.9</span> Covariance</h2>
<p>Covariance is the index which shows the relations of two variables. It is calculated as mean of deviations of two variables. As the value of covariance gets larger (in both positive and negative directions), which means that the correlation of two variables is strong, if the value is close to zero, which means there is almost no relations between two variables.
The following figure shows the shape of covariance matrix.
<span class="math display">\[
{\sum =} \genfrac[]{0pt}{2}{Var(x) Cov(x,y)}{Cov(x,y) Var(y)} 
\]</span></p>
<div class="figure">
<img src="covariance.png" alt="© Alto, 2019" style="width:60.0%" />
<p class="caption">© Alto, 2019</p>
</div>
</div>
<div id="references" class="section level2">
<h2><span class="header-section-number">2.10</span> References</h2>
<p>Alto.V.(2019).PCA: Eigenvectors and Eigenvalues. Towards data science. [online].Retrieved from <a href="https://towardsdatascience.com/pca-eigenvectors-and-eigenvalues-1f968bc6777a" class="uri">https://towardsdatascience.com/pca-eigenvectors-and-eigenvalues-1f968bc6777a</a> [accessed on 14.06.2020].</p>
<p>Garrett.G. and Wickham.H.(2017). R for Data science. O’Reilly.</p>
<p>Jolloffe.I. and Cadima.J. (2016). Principal component analysis: a review and recent developments. The royal society publishing.[online].Retrieved from <a href="https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0202" class="uri">https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0202</a> [accessed on 14.06.2020].</p>
<p>Kassambara.A. (2017). Articles - Principal Component Methods in R: Practical Guide. CA - Correspondence Analysis in R: Essentials. [online]. Retrieved from <a href="http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/113-ca-correspondence-analysis-in-r-essentials/" class="uri">http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/113-ca-correspondence-analysis-in-r-essentials/</a> [accessed on 15.06.2020].</p>
<p>Kassambara.A. (2017). Practical Guide To Cluster Analysis in R. sthda.com . Edition 1.</p>
<p>Le Roux.B.and Rouanet.H. (2004). Geometric Data Analysis. Kluwer Academic Publishers.</p>
<p>MathsisFun (2019).Eigenvector and Eigenvalue. [online].Retrieved from <a href="https://www.mathsisfun.com/algebra/eigenvalue.html" class="uri">https://www.mathsisfun.com/algebra/eigenvalue.html</a> [accessed on 14.06.2020].</p>
<p>Navlani.A. (2019). Introduction to Factor Analysis in Python. DataCamp. [online].Retrieved from <a href="https://www.datacamp.com/community/tutorials/introduction-factor-analysis?utm_source=adwords_ppc&amp;utm_campaignid=898687156&amp;utm_adgroupid=48947256715&amp;utm_device=c&amp;utm_keyword=&amp;utm_matchtype=b&amp;utm_network=g&amp;utm_adpostion=&amp;utm_creative=229765585186&amp;utm_targetid=aud-299261629574:dsa-429603003980&amp;utm_loc_interest_ms=&amp;utm_loc_physical_ms=1003088&amp;gclid=EAIaIQobChMIoo7Oy_GB6gIViBsYCh2diAVmEAAYASAAEgIEUfD_BwE" class="uri">https://www.datacamp.com/community/tutorials/introduction-factor-analysis?utm_source=adwords_ppc&amp;utm_campaignid=898687156&amp;utm_adgroupid=48947256715&amp;utm_device=c&amp;utm_keyword=&amp;utm_matchtype=b&amp;utm_network=g&amp;utm_adpostion=&amp;utm_creative=229765585186&amp;utm_targetid=aud-299261629574:dsa-429603003980&amp;utm_loc_interest_ms=&amp;utm_loc_physical_ms=1003088&amp;gclid=EAIaIQobChMIoo7Oy_GB6gIViBsYCh2diAVmEAAYASAAEgIEUfD_BwE</a> [ accessed on 15.06.2020].</p>
<p>Patili.P. (2018).What is Exploratory Data Analysis? Towards Data Science. [online]. Retrieved from <a href="https://towardsdatascience.com/exploratory-data-analysis-8fc1cb20fd15%5Baccessed" class="uri">https://towardsdatascience.com/exploratory-data-analysis-8fc1cb20fd15[accessed</a> on 14.06.2020].</p>
<p>Rahn.M.Factor Analysis: A Short Introduction, Part 1. The analysis factor.[online].Retrieved from <a href="https://www.theanalysisfactor.com/factor-analysis-1-introduction/#" class="uri">https://www.theanalysisfactor.com/factor-analysis-1-introduction/#</a>:~:text=In%20every%20factor%20analysis%2C%20there,factors%20as%20there%20are%20variables.&amp;text=The%20eigenvalue%20is%20a%20measure,than%20a%20single%20observed%20variable.[accessed on 16.07.2020].</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="glossary-2-pca.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Bookdown-MarinaObata2.pdf", "Bookdown-MarinaObata2.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
